{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07-Text-1",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP0WB9Lk90ls"
      },
      "source": [
        "# LEARNING GOALS\n",
        "#\n",
        "#                 - text as a datasource\n",
        "#                 - cleaning text\n",
        "#                 - basic eda\n",
        "#                 - Doc Term Matrix representation by hand\n",
        "#                 - The intuition behind working with text before jumping into tools that abstract this away\n",
        "#                 - how text can be used in ML\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJJaigOy9ylQ"
      },
      "source": [
        "# some helpful resources:\n",
        "# https://www.w3schools.com/python/python_regex.asp\n",
        "# https://docs.python.org/3/library/re.html\n",
        "# https://www.debuggex.com/cheatsheet/regex/python\n",
        "# https://www.shortcutfoo.com/app/dojos/python-regex/cheatsheet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAuyoLsOLJkF"
      },
      "source": [
        "# installs\n",
        "# ! pip install newspaper3k\n",
        "# ! pip install -U spacy\n",
        "# ! pip install wordcloud\n",
        "# ! pip install emoji\n",
        "# ! pip install nltk\n",
        "# ! pip install scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwjWwq_SLRq7"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplot\n",
        "\n",
        "# some \"fun\" new packages\n",
        "from wordcloud import WordCloud\n",
        "import emoji\n",
        "\n",
        "import re\n",
        "\n",
        "# new imports for text specific tasks\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer  \n",
        "import nltk\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hhnSSlrLY6G"
      },
      "source": [
        "# a = ['I like turtles!',\n",
        "#      'You like hockey and golf ',\n",
        "#      'Turtles and hockey ftw',\n",
        "#      'Python is very easy to learn. üêç',\n",
        "#      'A great resource is www.spacy.io',\n",
        "#      ' Today is the Feb 22, 2021 !           ',\n",
        "#      '@username #hashtag https://www.text.com',\n",
        "#      'BA820 ']\n",
        "\n",
        "# df = pd.DataFrame({'text':a})\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBpxLkHfMqiv"
      },
      "source": [
        "## QUICK QUESTION\n",
        "##        What do you see about the data being brought in?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWoJILfeNMvG"
      },
      "source": [
        "## we can always get the values back\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yv7wRHAFMFqe"
      },
      "source": [
        "# quick review of some of the string funcationality\n",
        "# we saw in 760\n",
        "\n",
        "# capitalize or change case\n",
        "# upper, lower, strip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM6ebG30MFkj"
      },
      "source": [
        "# we can detect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRTvt3OtMFdx"
      },
      "source": [
        "# remember python is case sensitive!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSRq0Kz3Pqxd"
      },
      "source": [
        "# we can replace anything that matches a pattern\n",
        "# but we will come back to patterns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xlAnbp9EajW"
      },
      "source": [
        "# we can look at the length\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQQE-097RVu5"
      },
      "source": [
        "#### NOTE:\n",
        "##      but look at above, what do you notice about the lengths calculated?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RroUtCMhSd3b"
      },
      "source": [
        "# lets look at the values directly again for the last entry\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlNyr7fREdDd"
      },
      "source": [
        "# lets count characters and numbers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-UfYjJJLRxS"
      },
      "source": [
        "## regex\n",
        "## https://www.regular-expressions.info/quickstart.html\n",
        "##\n",
        "## https://regex101.com/     <------------- fantastic resource\n",
        "##\n",
        "## [a-z] will match a single letter lowercase a to z\n",
        "## [A-Z] will match a single letter uppercase A to Z\n",
        "## [a-zA-Z0-9] will match a single character that is alphanumeric\n",
        "## ^ matches a pattern at the start\n",
        "## $ matches a pattern at the end\n",
        "## + will match a pattern one or more times\n",
        "## * will match 0 or more\n",
        "## .* will match everything (dot is any character)\n",
        "## {3} match pattern exactly 3 times\n",
        "## {2,4} match a pattern 2 to 4 times\n",
        "## {3, } match a pattern 3 or more times\n",
        "## | allows us to specify \"or\"\n",
        "## so much more including special patterns and shortcuts\n",
        "## \\d for a digit\n",
        "## \\w for word characters\n",
        "## \\s for whitespace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCqqYOMjVWOd"
      },
      "source": [
        "# only print out entries if the pattern matches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dBwYTI1VWHX"
      },
      "source": [
        "# again, case sensitive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCazcb-0VWCJ"
      },
      "source": [
        "# we can use \"OR\" logic\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HS_lr7sVT5W"
      },
      "source": [
        "# matches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKM7jqMNXwph"
      },
      "source": [
        "# more matches\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtB6Rz4ZX6OZ"
      },
      "source": [
        "# special characters anywhere - digits\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wOgQFCvsEH0"
      },
      "source": [
        "# extract username or hashtag\n",
        "# uses not whitespace character, repeating 1+\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRGdAfkXsNAZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTmquoontJB1"
      },
      "source": [
        "# you may get an error around capture groups\n",
        "# a group is in parentheses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAJh6kGrKyTK"
      },
      "source": [
        "> Regular expressions and searching text can be a superpower when working with text.  If we have a large corpus, we can interate over the documents and scan/search via regular expressions to extract our datasets!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNyrcUJAkzH5"
      },
      "source": [
        "## Thought Exercise:\n",
        "##    Our datasets that we typically see take the shape of:\n",
        "##    Rows =    Observations\n",
        "##    Columns = Attributes about those Observations\n",
        "## \n",
        "##    How can we map this to text?\n",
        "##\n",
        "##    Rows =    A document (the source, we will talk about this)\n",
        "##    Columns = The words in the document\n",
        "##   \n",
        "##    Above can be referred to as a Document Term Matrix, or Document Feature Matrix\n",
        "##\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpgwsaQsTGb9"
      },
      "source": [
        "# lets reset the dataframe\n",
        "\n",
        "# df = pd.DataFrame({'doc':a})\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pupq6P8KTGef"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-XXjZCFUB5X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWB8hamtUIpu"
      },
      "source": [
        "# if we really wanted to (or had to), we \n",
        "# have the python chops to make this a doc/term matrix\n",
        "\n",
        "# step 0, just the tokens but keep as a dataframe\n",
        "# tdf = df[['tokens']]\n",
        "\n",
        "# step 1: melt it via explode\n",
        "# tdf_long = tdf.explode(\"tokens\")\n",
        "# tdf_long"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WL7E1O5UZz1"
      },
      "source": [
        "# step 3: back to wide for a dtm\n",
        "# tdf_long['value'] = 1\n",
        "# dtm = tdf_long.pivot_table(columns=\"tokens\", \n",
        "#                            values=\"value\", \n",
        "#                            index=tdf_long.index,\n",
        "#                            aggfunc=np.count_nonzero)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqmgKNUKUag1"
      },
      "source": [
        "# lets review what we have\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wzl5xygVcGe"
      },
      "source": [
        "## Quick thought exercise:\n",
        "##      What do you notice about our tokenized dataset\n",
        "##      What about the values?  What would you change?\n",
        "##   \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbtVFg-GbPB_"
      },
      "source": [
        "################ YOUR TURN\n",
        "##  from the topics table on big query (questrom.datasets.topics), \n",
        "##  bring in just the text column via select\n",
        "##  Make the text lowercase\n",
        "##  Tricky!! remove punctuation if you can (keep just letters and numbers)\n",
        "##  get the text into a long form where each token is a row in the dataframe\n",
        "##  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFRyr5ejcfML"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHHwhJhGcmGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbQ5p4tndcWZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9JcrWXMfATQ"
      },
      "source": [
        "# just highlighting what is possible, you don't need to do this\n",
        "# keep just the numbers and letters\n",
        "# just highlighting that depending on your use cases, you can \n",
        "# roll your own functions to clean text\n",
        "# pandas makes it easy to `apply` these to our text column!\n",
        "# def remove_punct(text):\n",
        "#   import string\n",
        "#   text = ''.join([p for p in text if p not in set(string.punctuation)])\n",
        "#   return text\n",
        "\n",
        "# topics['text'] = topics.text.apply(remove_punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqEDTuP8oYYp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cChf_EVLcStR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQBhFljHmq5A"
      },
      "source": [
        "#################################### Lets predict the category!\n",
        "##\n",
        "## we now have a dataset that can be used to fit a ML model.  \n",
        "## the quality of the models and how we think about ML tasks is all about the data\n",
        "## let's start with this framing for intuition\n",
        "##\n",
        "##\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrE560owfMkh"
      },
      "source": [
        "## get the topics data again\n",
        "\n",
        "# topics = pd.read_gbq(\"SELECT * from `questrom.datasets.topics`\", \"questrom\")\n",
        "# topics.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLo2HLBDfaHu"
      },
      "source": [
        "# what do we have\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTHPmPScfh2N"
      },
      "source": [
        "# what do we have for a distro on topics?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udxGSGrAnKEA"
      },
      "source": [
        "# imports -- violating my rule of thumb, but lets put that aside for emphasis\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn import metrics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yFauZSpdLBY"
      },
      "source": [
        "# remember, we have the topics data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpQPpKxFuvWg"
      },
      "source": [
        "# we can tokenize our data with sklearn pipelines\n",
        "# above highlights we have full control, but there are frameworks that aim to abstract this for us\n",
        "# abstractions have their own overhead costs, but lets build on top of sklearn to soften the impact\n",
        "\n",
        "# cv = CountVectorizer()\n",
        "# cv.fit(topics.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I29-3YTVd6eP"
      },
      "source": [
        "# we can easily have done fit_transform, but lets explore what was learned about our corpus\n",
        "\n",
        "# get the vocabulary and their term:numeric id map\n",
        "# this is a common representation for downstream word embedding tasks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Burb8GQtd6jM"
      },
      "source": [
        "# length\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPn7ePyVd6mE"
      },
      "source": [
        "## make this a numeric matrix of document by term (dtm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHPSUQrGhPWb"
      },
      "source": [
        "# confirm the shape is what we expect\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR51mZ5zimnD"
      },
      "source": [
        "# missing data are zeros\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW14oyJcMIOV"
      },
      "source": [
        "# make this a dataframe to help with our mental model\n",
        "\n",
        "# dtm_df = pd.DataFrame(dtm.toarray(), columns=cv.get_feature_names())\n",
        "# dtm_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZTkhThano-q"
      },
      "source": [
        "# lets build the datasets for the model\n",
        "\n",
        "# X = dtm_df.copy()\n",
        "# y = topics.topic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ_uhzCgyDtj"
      },
      "source": [
        "# confirm we have the same thing\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebd6xhbPBozJ"
      },
      "source": [
        "# split the data\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=820)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkaye_UrovCU"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "# tree = DecisionTreeClassifier(max_depth=5, min_samples_split=30, min_samples_leaf=15)\n",
        "# tree.fit(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uca_rPMDyhdP"
      },
      "source": [
        "# fit metrics on test\n",
        "\n",
        "# preds = tree.predict(X_test)\n",
        "# ctable = metrics.classification_report(y_test, preds)\n",
        "# print(ctable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6U9hpQ-yoTI"
      },
      "source": [
        "# confusion matrix from skplot\n",
        "# cancan see where the model isn't sure\n",
        "\n",
        "# skplot.metrics.plot_confusion_matrix(y_test, preds, \n",
        "#                                      figsize=(7,4), \n",
        "#                                      x_tick_rotation=90 )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVokMjD_kSKJ"
      },
      "source": [
        "# accuracy score   <----- confirming the classification report\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf56BZoIzFiF"
      },
      "source": [
        "#################################### REVIEW\n",
        "##\n",
        "## - normal text form -> a DTM\n",
        "## - we saw that tokenizing, and the logic we apply, matters (case, punctuation)\n",
        "#     will we see even more example\n",
        "## - if we had to, we can parse text into a format for machine learning\n",
        "## - nothing stopping us from passing in a count-based dtm into a ML model!\n",
        "## "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9aezQCJzGUF"
      },
      "source": [
        "############################################################\n",
        "########################################### Team Challenge\n",
        "############################################################\n",
        "# \n",
        "## Work in Project Groups\n",
        "# \n",
        "# - tokenize the dataset on Big Query from \n",
        "# URL link: https://console.cloud.google.com/bigquery?project=questrom&d=SMSspam&\n",
        "\n",
        "## review the slides at the end of this module\n",
        "## predict spam\n",
        "## objetive =  based on f1\n",
        "## only input is text, but you can derive features\n",
        "## limited time, but how do you maximize your time (and the model?)\n",
        "## HINTS:\n",
        "##        start small, simple models\n",
        "##        iterate and see how you do against the leaderboard\n",
        "##        code above helps you with the core mechanics\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S5I5U88mI8g"
      },
      "source": [
        "# get the datasets - select * is fine, but there are two datasets and an example submission to review!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1KZd2DxpJcx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lklSYyShmX07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhINuqBEPCO-"
      },
      "source": [
        "! head myteam-submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-la3lDT8PuRo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}